{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A57R4L/LUTModelTraining/blob/main/LUT_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEc2_77R1Trn"
      },
      "source": [
        "\n",
        "## Initialize parameters and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL9kRci7p1bg",
        "outputId": "11233329-25e7-42ce-c696-ef0b494ae748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook running on: cuda:0\n"
          ]
        }
      ],
      "source": [
        "## Import libraries\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pp\n",
        "import random\n",
        "\n",
        "# For downloading from Google Colab\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "# For execution time metrics\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "# For image tests\n",
        "from PIL import Image\n",
        "from skimage import util\n",
        "\n",
        "# Try to use GPU if available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Notebook running on:', device)\n",
        "\n",
        "# Default full parameters\n",
        "\n",
        "# Number of Grading Parameters to include in the training\n",
        "nGradingParameters = 10\n",
        "# Number of observations/samples - how much training material we create\n",
        "nSamples = 1024\n",
        "# Hidden Layer Input size, For 1-2 parameters 10 was enough, 32 for 5, 48 for 10\n",
        "nHidden = 48\n",
        "# Batch size, initially 32, tried 64 for 10 parameters\n",
        "nBatchSize = 32\n",
        "# Training Steps (epochs)\n",
        "nTrainSteps = 50000\n",
        "# Training Seed (Sobol Intialization value, can also be used to invalidate pre-generated training data)\n",
        "sobolSeed = 1337\n",
        "# Learnin rate\n",
        "lRate = 1e-3\n",
        "\n",
        "# Force sample regeneration (will skip existing sample data)\n",
        "forceSampleGeneration=False\n",
        "# Skip model regeneration is one exists in the local folder\n",
        "skipModelRegeneration=True\n",
        "# Skip saving local files\n",
        "skipSave=False\n",
        "# Download (if not running locally, ie. Google Colab)\n",
        "DOWNLOAD=False\n",
        "## For requesting upload of external data to Google Colab - will be ignored if local data exists\n",
        "UPLOADSAMPLES=False\n",
        "\n",
        "try:\n",
        " from google.colab import files\n",
        "except:\n",
        " print('Not in Google Colab. Disabling download and upload request')\n",
        " DOWNLOAD=False\n",
        " UPLOADSAMPLES=False\n",
        "\n",
        "# Demo preset\n",
        "DEMO=''\n",
        "\n",
        "# Number of tests for the plot\n",
        "nTests = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZOipNEG72Vn",
        "outputId": "fd2c3905-a4d4-4df4-bf6c-80244396e650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running notebook with preset: All1\n",
            "Colorgrading parameters to analyse: 12\n",
            "LUT samples to generate: 4096\n",
            "Hidden layer inputs: 128\n",
            "Training steps for NN training: 5000\n",
            "Batch size: 64\n",
            "Learning rate:  0.001\n",
            "Test size: 128\n"
          ]
        }
      ],
      "source": [
        "# Presets for trying notebook with various presets\n",
        "#\n",
        "# Fast - 1 grading parameter (Saturation) - 128 samples - 10 hidden layers - 2000 epochs\n",
        "# Medium - 2 grading parameters (Sat + Contrast) - 256 samples - 16 hidden layers - 3000 epochs\n",
        "# Slow - 5 grading parameters (Full Sat + Contrast) - 512 samples - 32 hidden layers - 15000 epochs\n",
        "# Full - 10 grading parameters (Full grading) - 1024 samples - 48 hidden layers - 50000 epochs\n",
        "\n",
        "DEMO='All1'\n",
        "# DEMO='Medium'\n",
        "# DEMO='Slow'\n",
        "# DEMO='Full'\n",
        "\n",
        "## Assign preset values\n",
        "preset=False\n",
        "\n",
        "if DEMO == 'Fast':\n",
        "  nGradingParameters = 1\n",
        "  nSamples = 128\n",
        "  nHidden = 10\n",
        "  nTrainSteps = 2000\n",
        "  lRate = 1e-4\n",
        "  preset=True\n",
        "\n",
        "if DEMO == 'Medium':\n",
        "  nGradingParameters = 2\n",
        "  nSamples = 256\n",
        "  nHidden = 16\n",
        "  nTrainSteps = 3000\n",
        "  lRate = 1e-4\n",
        "  preset=True\n",
        "\n",
        "if DEMO == 'Slow':\n",
        "  nGradingParameters = 5\n",
        "  nSamples = 512\n",
        "  nHidden = 16\n",
        "  nTrainSteps = 15000\n",
        "  preset=True\n",
        "\n",
        "if DEMO == 'Slow2':\n",
        "  nGradingParameters = 5\n",
        "  nSamples = 2048\n",
        "  nHidden = 48\n",
        "  nTrainSteps = 15000\n",
        "  nBatchSize = 64\n",
        "  preset=True\n",
        "\n",
        "if DEMO == 'Full':\n",
        "  nGradingParameters = 10\n",
        "  nSamples = 1024\n",
        "  nHidden = 48\n",
        "  nTrainSteps = 50000\n",
        "  nTests = 256\n",
        "  preset=True\n",
        "\n",
        "# Semi consistent results already except Gain W\n",
        "if DEMO == 'Full2':\n",
        "  nGradingParameters = 10\n",
        "  nSamples = 2048\n",
        "  nHidden = 128\n",
        "  nTrainSteps = 25000\n",
        "  nTests = 256\n",
        "  nBatchSize = 64\n",
        "  lRate = 1e-3\n",
        "  preset=True\n",
        "\n",
        "# No W multipliers, just direct RGB\n",
        "if DEMO == 'All1':\n",
        "  nGradingParameters = 12\n",
        "  nSamples = 4096\n",
        "  nHidden = 128\n",
        "  nTrainSteps = 5000\n",
        "  nTests = 128\n",
        "  nBatchSize = 64\n",
        "  lRate = 1e-3\n",
        "  preset=True\n",
        "\n",
        "if preset == True:\n",
        "  print('Running notebook with preset:', DEMO)\n",
        "else:\n",
        "  print('Running notebook with Custom Settings')\n",
        "\n",
        "print('Colorgrading parameters to analyse:', nGradingParameters)\n",
        "print('LUT samples to generate:', nSamples)\n",
        "print('Hidden layer inputs:', nHidden)\n",
        "print('Training steps for NN training:', nTrainSteps)\n",
        "print('Batch size:', nBatchSize)\n",
        "print('Learning rate: ', lRate)\n",
        "print('Test size:', nTests)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRR_kF1d1jw7"
      },
      "source": [
        "## Define Colorgrading Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-cEDAucEbsZ"
      },
      "outputs": [],
      "source": [
        "# Helper functions and handpicked definitions for data creation\n",
        "# Grading functions are applied component-wise, implemented here per scalar for the sake of clarity\n",
        "\n",
        "# Parameters are hardcoded in the start of this cell and here in functions initParameters and grade (unpacking parameters)\n",
        "\n",
        "# Size of a dimension of the Look-up Texture (16 x 16 x 16)\n",
        "LUT_SIZE = 16\n",
        "\n",
        "# Saturation\n",
        "P_SAT = 1.0\n",
        "P_SAT_LOW = 0.50\n",
        "P_SAT_HIGH = 1.50\n",
        "\n",
        "P_SAT2_LOW = 0.50\n",
        "P_SAT2_HIGH = 1.50\n",
        "\n",
        "P_SAT_R = 1.0\n",
        "P_SAT_G = 1.0\n",
        "P_SAT_B = 1.0\n",
        "P_SAT_R_LOW = P_SAT2_LOW\n",
        "P_SAT_G_LOW = P_SAT2_LOW\n",
        "P_SAT_B_LOW = P_SAT2_LOW\n",
        "P_SAT_R_HIGH = P_SAT2_HIGH\n",
        "P_SAT_G_HIGH = P_SAT2_HIGH\n",
        "P_SAT_B_HIGH = P_SAT2_HIGH\n",
        "\n",
        "# Contrast\n",
        "P_CON = 1.0\n",
        "P_CON_LOW = 0.50\n",
        "P_CON_HIGH = 1.50\n",
        "\n",
        "P_CON2_LOW = 0.50\n",
        "P_CON2_HIGH = 1.50\n",
        "\n",
        "P_CON_R = 1.0\n",
        "P_CON_G = 1.0\n",
        "P_CON_B = 1.0\n",
        "P_CON_R_LOW = P_CON2_LOW\n",
        "P_CON_G_LOW = P_CON2_LOW\n",
        "P_CON_B_LOW = P_CON2_LOW\n",
        "P_CON_R_HIGH = P_CON2_HIGH\n",
        "P_CON_G_HIGH = P_CON2_HIGH\n",
        "P_CON_B_HIGH = P_CON2_HIGH\n",
        "\n",
        "# Gamma\n",
        "P_GAM = 1.0\n",
        "P_GAM_LOW = 0.50\n",
        "P_GAM_HIGH = 1.50\n",
        "\n",
        "P_GAM2_LOW = 0.50\n",
        "P_GAM2_HIGH = 1.50\n",
        "\n",
        "P_GAM_R = 1.0\n",
        "P_GAM_G = 1.0\n",
        "P_GAM_B = 1.0\n",
        "P_GAM_R_LOW = P_GAM2_LOW\n",
        "P_GAM_G_LOW = P_GAM2_LOW\n",
        "P_GAM_B_LOW = P_GAM2_LOW\n",
        "P_GAM_R_HIGH = P_GAM2_HIGH\n",
        "P_GAM_G_HIGH = P_GAM2_HIGH\n",
        "P_GAM_B_HIGH = P_GAM2_HIGH\n",
        "\n",
        "# Gain\n",
        "P_GIN = 1.0\n",
        "P_GIN_LOW = 0.50\n",
        "P_GIN_HIGH = 1.50\n",
        "\n",
        "P_GIN2_LOW = 0.50\n",
        "P_GIN2_HIGH = 1.50\n",
        "\n",
        "P_GIN_R = 1.0\n",
        "P_GIN_G = 1.0\n",
        "P_GIN_B = 1.0\n",
        "P_GIN_R_LOW = P_GIN2_LOW\n",
        "P_GIN_G_LOW = P_GIN2_LOW\n",
        "P_GIN_B_LOW = P_GIN2_LOW\n",
        "P_GIN_R_HIGH = P_GIN2_HIGH\n",
        "P_GIN_G_HIGH = P_GIN2_HIGH\n",
        "P_GIN_B_HIGH = P_GIN2_HIGH\n",
        "\n",
        "if nGradingParameters < 12:\n",
        "  P_ALL_LOW = np.array([P_SAT_LOW, P_CON_LOW, P_SAT_R_LOW, P_SAT_G_LOW, P_SAT_B_LOW, P_GAM_LOW, P_GIN_LOW, P_GIN_R_LOW, P_GIN_G_LOW, P_GIN_B_LOW])\n",
        "  P_ALL_HIGH = np.array([P_SAT_HIGH, P_CON_HIGH, P_SAT_R_HIGH, P_SAT_G_HIGH, P_SAT_B_HIGH, P_GAM_HIGH, P_GIN_HIGH, P_GIN_R_HIGH, P_GIN_G_HIGH, P_GIN_B_HIGH])\n",
        "else:\n",
        "  P_ALL_LOW = np.array([P_SAT_R_LOW, P_SAT_G_LOW, P_SAT_B_LOW, P_CON_R_LOW, P_CON_G_LOW, P_CON_B_LOW, P_GAM_R_LOW, P_GAM_G_LOW, P_GAM_B_LOW, P_GIN_R_LOW, P_GIN_G_LOW, P_GIN_B_LOW])\n",
        "  P_ALL_HIGH = np.array([P_SAT_R_HIGH, P_SAT_G_HIGH, P_SAT_B_HIGH, P_CON_R_HIGH, P_CON_G_HIGH, P_CON_B_HIGH, P_GAM_R_HIGH, P_GAM_G_HIGH, P_GAM_B_HIGH, P_GIN_R_HIGH, P_GIN_G_HIGH, P_GIN_B_HIGH])\n",
        "\n",
        "# Parameter list\n",
        "def initParameters():\n",
        "  if nGradingParameters < 2:\n",
        "    paramlist = np.array([P_SAT])\n",
        "    return paramlist\n",
        "  if nGradingParameters < 3:\n",
        "    paramlist = np.array([P_SAT, P_CON])\n",
        "    return paramlist\n",
        "  if nGradingParameters < 6:\n",
        "    paramlist = np.array([P_SAT, P_CON, P_SAT_R, P_SAT_G, P_SAT_B])\n",
        "    return paramlist\n",
        "  if nGradingParameters < 12:\n",
        "    paramlist = np.array([P_SAT, P_CON, P_SAT_R, P_SAT_G, P_SAT_B, P_GAM, P_GIN, P_GIN_R, P_GIN_G, P_GIN_B])\n",
        "    return paramlist\n",
        "  paramlist = np.array([P_SAT_R, P_SAT_G, P_SAT_B, P_CON_R, P_CON_G, P_CON_B, P_GAM_R, P_GAM_G, P_GAM_B, P_GIN_R, P_GIN_G, P_GIN_B])\n",
        "  return paramlist\n",
        "\n",
        "# Full default\n",
        "def initFullParameters():\n",
        "  if nGradingParameters == 12:\n",
        "    paramlist = np.array([P_SAT_R, P_SAT_G, P_SAT_B, P_CON_R, P_CON_G, P_CON_B, P_GAM_R, P_GAM_G, P_GAM_B, P_GIN_R, P_GIN_G, P_GIN_B])\n",
        "  else:\n",
        "    paramlist = np.array([P_SAT, P_CON, P_SAT_R, P_SAT_G, P_SAT_B, P_GAM, P_GIN, P_GIN_R, P_GIN_G, P_GIN_B])\n",
        "  return paramlist\n",
        "\n",
        "# Random parameters (random generated (for plotting), even distribution quasirandom (for generation) method defined later)\n",
        "def randomParameters():\n",
        "  rndparam = initParameters()\n",
        "  for i in np.ndindex(rndparam.shape):\n",
        "    rndparam[i] = random.uniform(P_ALL_LOW[i], P_ALL_HIGH[i])\n",
        "  return rndparam\n",
        "\n",
        "# String from parameters - for creating output filenames and printing results\n",
        "def createParameterString(px, py):\n",
        "    pStr = f'CUSTOM{px[0]:.2f}v{py[0]:.2f}'\n",
        "    match nGradingParameters:\n",
        "      case (1):\n",
        "        pStr = f'SAT{px[0]:.2f}v{py[0]:.2f}'\n",
        "      case (2):\n",
        "        pStr = f'SAT{px[0]:.2f}v{py[0]:.2f}_CON{px[1]:.2f}v{py[1]:.2f}'\n",
        "      case (5):\n",
        "        pStr = f'SAT{px[0]:.2f}v{py[0]:.2f}_CON{px[1]:.2f}v{py[1]:.2f}_SATR{px[2]:.2f}v{py[2]:.2f}_SATG{px[3]:.2f}v{py[3]:.2f}_SATB{px[4]:.2f}v{py[4]:.2f}'\n",
        "      case (10):\n",
        "        pStr = f'SAT{px[0]:.2f}v{py[0]:.2f}_CON{px[1]:.2f}v{py[1]:.2f}_GAM{px[5]:.2f}v{py[5]:.2f}_GIN{px[6]:.2f}v{py[6]:.2f}'\n",
        "      case (12):\n",
        "        pStr = f'SAT{px[0]:.2f}r{px[1]:.2f}g{px[2]:.2f}bx{py[0]:.2f}r{py[1]:.2f}g{py[2]:.2f}b_CON{px[3]:.2f}r{px[4]:.2f}g{px[5]:.2f}bx{py[3]:.2f}r{py[4]:.2f}g{py[5]:.2f}_GAM{px[6]:.2f}r{px[7]:.2f}g{px[8]:.2f}bx{py[6]:.2f}r{py[7]:.2f}g{py[8]:.2f}_GIN{px[9]:.2f}r{px[10]:.2f}g{px[11]:.2f}bx{py[9]:.2f}r{py[10]:.2f}g{py[11]:.2f}'\n",
        "    return pStr\n",
        "\n",
        "# Number of parameters (for model training and benchmarking)\n",
        "P_DEFAULT = initParameters()\n",
        "# P_ALL = initParameters()\n",
        "#P_ALL = np.array([P_SAT, P_CON])\n",
        "nParameters = P_DEFAULT.size\n",
        "\n",
        "# Transformations\n",
        "RGB2Y = [0.2722287168, 0.6740817658, 0.0536895174]\n",
        "\n",
        "# with CAT02 chromatic adaptation transform\n",
        "SRGB2ACEScg = [[ 0.61311781, 0.34118200,  0.04578734], [ 0.06993408, 0.91810304, 0.01193278], [ 0.02046299,  0.10676866, 0.87271591]]\n",
        "ACEScg2SRGB = [[ 1.70488733, -0.62415727, -0.08088677], [-0.12952094,  1.13839933, -0.00877924], [-0.02412706, -0.12462061,  1.14882211]]\n",
        "\n",
        "# Create default LUT\n",
        "# LUT is 16 x 16 x 16 projected as 256 x 16 2D Texture\n",
        "def initLUT():\n",
        "  default_lut = np.zeros((16,256,3), dtype=np.float32)\n",
        "  r = 0\n",
        "  g = 0\n",
        "  b = 0\n",
        "  # Lutstep needs to be one less for range of 0..1\n",
        "  lutstep = 1/(LUT_SIZE -1)\n",
        "\n",
        "  # Note to self: careful with the channel order/how LUT is saved\n",
        "  for i in np.ndindex(default_lut.shape[:2]):\n",
        "    default_lut[i] = [r, g, b]\n",
        "    r = r + lutstep\n",
        "    if (r >= 1):\n",
        "      r = 0\n",
        "      b = b + lutstep\n",
        "      if (b >= 1):\n",
        "        b = 0\n",
        "        g = g + lutstep\n",
        "\n",
        "  return default_lut\n",
        "\n",
        "# 3x3 matrix multiplication for colorspace transform (alpha or >3 components are not handled)\n",
        "def mult_vector3_matrix3(v, m):\n",
        "    vOut = [m[0][0] * v[0] + m[0][1] * v[1] + m[0][2] * v[2],\n",
        "            m[1][0] * v[0] + m[1][1] * v[1] + m[1][2] * v[2],\n",
        "            m[2][0] * v[0] + m[2][1] * v[1] + m[2][2] * v[2]]\n",
        "    return vOut\n",
        "\n",
        "# Linear interpolation between two colors\n",
        "def lerp(color1, color2, value):\n",
        "  color_out = [0.0, 0.0, 0.0]\n",
        "  color_out[0] = color1[0] * (1.0 - value[0]) + color2[0] * value[0]\n",
        "  color_out[1] = color1[1] * (1.0 - value[1]) + color2[1] * value[1]\n",
        "  color_out[2] = color1[2] * (1.0 - value[2]) + color2[2] * value[2]\n",
        "\n",
        "  return color_out\n",
        "\n",
        "# Luminance value of a pixel\n",
        "def luma(inputcolor):\n",
        "  luma = np.dot(RGB2Y, inputcolor)\n",
        "  return luma\n",
        "\n",
        "# Per pixel Color Grading Function\n",
        "def grade(inputcolor, parameters):\n",
        "  # Unpack parameters for clarity\n",
        "  if nGradingParameters == 12:\n",
        "    P_SAT_R = parameters[0]\n",
        "    P_SAT_G = parameters[1]\n",
        "    P_SAT_B = parameters[2]\n",
        "    P_CON_R = parameters[3]\n",
        "    P_CON_G = parameters[4]\n",
        "    P_CON_B = parameters[5]\n",
        "    P_GAM_R = parameters[6]\n",
        "    P_GAM_G = parameters[7]\n",
        "    P_GAM_B = parameters[8]\n",
        "    P_GIN_R = parameters[9]\n",
        "    P_GIN_G = parameters[10]\n",
        "    P_GIN_B = parameters[11]\n",
        "    P_SAT = 1.0\n",
        "    P_CON = 1.0\n",
        "    P_GIN = 1.0\n",
        "    P_GAM = 1.0\n",
        "  else:\n",
        "    P_SAT = parameters[0]\n",
        "    P_CON = parameters[1]\n",
        "    P_SAT_R = parameters[2]\n",
        "    P_SAT_G = parameters[3]\n",
        "    P_SAT_B = parameters[4]\n",
        "    P_GAM = parameters[5]\n",
        "    P_GIN = parameters[6]\n",
        "    P_GIN_R = parameters[7]\n",
        "    P_GIN_G = parameters[8]\n",
        "    P_GIN_B = parameters[9]\n",
        "\n",
        "  ## Change colorspace sRGB > (ACEScg) AP1\n",
        "  inputcolor = mult_vector3_matrix3(inputcolor, SRGB2ACEScg)\n",
        "\n",
        "  ## Saturation\n",
        "  # Calculate luminance\n",
        "  color_luma = luma(inputcolor)\n",
        "  color_bw = [color_luma,color_luma,color_luma]\n",
        "  param_sat = [P_SAT * P_SAT_R, P_SAT * P_SAT_G, P_SAT * P_SAT_B]\n",
        "  color_sat = lerp(color_bw, inputcolor, param_sat)\n",
        "  # Saturation output can't have negative values\n",
        "  color_sat[0] = max(0, color_sat[0])\n",
        "  color_sat[1] = max(0, color_sat[1])\n",
        "  color_sat[2] = max(0, color_sat[2])\n",
        "\n",
        "  ## Contrast\n",
        "  param_con = [P_CON * P_CON_R, P_CON * P_CON_G, P_CON * P_CON_B]\n",
        "  color_con = [0.0, 0.0, 0.0]\n",
        "  color_con[0] = (pow(color_sat[0] * (1.0 / 0.18), param_con[0])) * 0.18\n",
        "  color_con[1] = (pow(color_sat[1] * (1.0 / 0.18), param_con[1])) * 0.18\n",
        "  color_con[2] = (pow(color_sat[2] * (1.0 / 0.18), param_con[2])) * 0.18\n",
        "\n",
        "  ## Gamma\n",
        "  param_gam = [P_GAM * P_GAM_R, P_GAM * P_GAM_G, P_GAM * P_GAM_B]\n",
        "  color_gam = [0.0, 0.0, 0.0]\n",
        "  color_gam[0] = pow(color_con[0], (1.0 / param_gam[0]))\n",
        "  color_gam[1] = pow(color_con[1], (1.0 / param_gam[1]))\n",
        "  color_gam[2] = pow(color_con[2], (1.0 / param_gam[2]))\n",
        "\n",
        "  ## Gain\n",
        "  param_gin = [P_GIN * P_GIN_R, P_GIN * P_GIN_G, P_GIN * P_GIN_B]\n",
        "  color_gin = [0.0, 0.0, 0.0]\n",
        "  color_gin[0] = color_gam[0] * param_gin[0]\n",
        "  color_gin[1] = color_gam[1] * param_gin[1]\n",
        "  color_gin[2] = color_gam[2] * param_gin[2]\n",
        "\n",
        "  # Offset is not applied as it doesn't feel relevant in this context (additive lift for all values)\n",
        "\n",
        "  ## Change colorspace (ACEScg) AP1 > sRGB\n",
        "  color_out = mult_vector3_matrix3(color_gin, ACEScg2SRGB)\n",
        "\n",
        "  return color_out\n",
        "\n",
        "# Grade call function for any image\n",
        "def applyGrade(img, parameters):\n",
        "  # Run grading function always with all parameters\n",
        "  gradeParams = initFullParameters()\n",
        "  gradeParams[0] = parameters[0]\n",
        "  # If not running full training, we don't have all parameters\n",
        "  if nGradingParameters > 1:\n",
        "    gradeParams[1] = parameters[1]\n",
        "  if nGradingParameters > 2:\n",
        "    gradeParams[2] = parameters[2]\n",
        "    gradeParams[3] = parameters[3]\n",
        "    gradeParams[4] = parameters[4]\n",
        "  if nGradingParameters > 5:\n",
        "    gradeParams[5] = parameters[5]\n",
        "    gradeParams[6] = parameters[6]\n",
        "    gradeParams[7] = parameters[7]\n",
        "    gradeParams[8] = parameters[8]\n",
        "    gradeParams[9] = parameters[9]\n",
        "  if nGradingParameters > 11:\n",
        "    gradeParams[10] = parameters[10]\n",
        "    gradeParams[11] = parameters[11]\n",
        "\n",
        "  for iy, ix, iz in np.ndindex(img.shape):\n",
        "      pixelCol = img[iy, ix]\n",
        "      gradedCol = grade(pixelCol, gradeParams)\n",
        "      img[iy, ix] = gradedCol\n",
        "  # clamp final colors to 0..1\n",
        "  np.clip(img, 0.0, 1.0, out=img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohAzAdfVvfDk"
      },
      "source": [
        "This cell applys the grading to a default LUT texture - for grading implementation debugging purposes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCQyVkJY1z-0"
      },
      "source": [
        "## Generate or Load Training Data: LUT samples & grading parameters\n",
        "\n",
        "Sample-creation is a n-dimensional problem which we tackle by using quasirandom sequence to generate parameters from their hand-picked range\n",
        "\n",
        "1024 samples generation took: 2min46s on Google T4 GPU - 1m 32s on Local Ryzen 9 5900x / NVidia 4070Ti 12GB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo9O6Sg5X-o1"
      },
      "outputs": [],
      "source": [
        "# With a few parameters we can easily just walk through the space with equally sized steps\n",
        "# However, with more parameters, the problem becomes n dimensional and we likely want to\n",
        "# sample the space in a way that doesn't require exponentially growing amount of samples\n",
        "#\n",
        "# We use a quasirandom sequence (Sobol) to fill the n dimensional space\n",
        "\n",
        "# Dimensions are defined by the amount of parameters\n",
        "# sobolspace = torch.quasirandom.SobolEngine(nParameters, scramble=True, seed=1337)\n",
        "\n",
        "sobolSamples = torch.zeros(nParameters)\n",
        "\n",
        "# Dimension of generated sample pool by number of samples we will generate eventually\n",
        "# sobolsamples = sobolspace.draw(nSamples, sobolsamples)\n",
        "\n",
        "def initSpace(inputseed, samples):\n",
        "  sobolspace = torch.quasirandom.SobolEngine(nParameters, scramble=True, seed=inputseed)\n",
        "  sobolSamples = sobolspace.draw(samples)\n",
        "  return sobolSamples\n",
        "\n",
        "def setParameter(p_low, p_high, id, iteration):\n",
        "  range = p_high - p_low\n",
        "  value = sobolSamples[iteration,id] * range\n",
        "  value += p_low\n",
        "  return value.detach().numpy()\n",
        "\n",
        "def getAllParameters(iteration):\n",
        "  currentParam = initParameters()\n",
        "  for i in np.ndindex(currentParam.shape):\n",
        "    currentParam[i] = setParameter(P_ALL_LOW[i], P_ALL_HIGH[i], i, iteration)\n",
        "  return currentParam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Fyw4MgguO2",
        "outputId": "3db87d4c-f5d7-488c-c696-72c97d521425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory found\n",
            "File: ./training_samples/allsamples_4096_12_1337.npy not found\n",
            "File: ./training_samples/allparameters_4096_12_1337.npy not found\n",
            "No pre-generated data found\n"
          ]
        }
      ],
      "source": [
        "# Trying to locate/upload pre-generated data\n",
        "LOCALDATA = False\n",
        "\n",
        "## Check if we have relevant training data locally\n",
        "SAMPLESPATH = './training_samples'\n",
        "LUTSAMPLESFILE = f'{SAMPLESPATH}/allsamples_{nSamples}_{nGradingParameters}_{sobolSeed}.npy'\n",
        "PARAMETERSFILE = f'{SAMPLESPATH}/allparameters_{nSamples}_{nGradingParameters}_{sobolSeed}.npy'\n",
        "\n",
        "if path.exists(SAMPLESPATH) == False:\n",
        "  LOCALDATA = False\n",
        "  os.mkdir(SAMPLESPATH)\n",
        "else:\n",
        "  print('Directory found')\n",
        "  if path.exists(LUTSAMPLESFILE) == False:\n",
        "    print(f'File: {LUTSAMPLESFILE} not found')\n",
        "    LOCALDATA = False\n",
        "  if path.exists(PARAMETERSFILE) == False:\n",
        "    print(f'File: {PARAMETERSFILE} not found')\n",
        "    LOCALDATA = False\n",
        "\n",
        "if LOCALDATA == False:\n",
        "  if UPLOADSAMPLES == True:\n",
        "    files.upload()\n",
        "\n",
        "if path.exists(LUTSAMPLESFILE) == True and path.exists(PARAMETERSFILE) == True:\n",
        "  LOCALDATA = True\n",
        "\n",
        "## Catch error (?)\n",
        "if LOCALDATA != True and LOCALDATA != False:\n",
        "  raise SystemExit(0)\n",
        "\n",
        "## Print status\n",
        "if LOCALDATA == True:\n",
        "  lut_data = np.load(LUTSAMPLESFILE)\n",
        "  print('Using pre-generated sample data from:',LUTSAMPLESFILE)\n",
        "  parameter_targets = np.load(PARAMETERSFILE)\n",
        "  print('Using pre-generated parameter data from:',PARAMETERSFILE)\n",
        "\n",
        "  # Check that the shape match\n",
        "  DATAOK = False\n",
        "  if lut_data.shape[0] == nSamples and lut_data.shape[1] == LUT_SIZE and lut_data.shape[2] == LUT_SIZE*LUT_SIZE and lut_data.shape[3] == 3:\n",
        "    if parameter_targets.shape[0] == nSamples and parameter_targets.shape[1] == nGradingParameters:\n",
        "      DATAOK = True\n",
        "\n",
        "  if DATAOK==False:\n",
        "    LOCALDATA = False\n",
        "    print('Error validating loaded data')\n",
        "    raise SystemExit(0)\n",
        "else:\n",
        "  print('No pre-generated data found')\n",
        "\n",
        "if forceSampleGeneration==True:\n",
        "  LOCALDATA = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD23mYtdsDF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c85c39-2943-42cd-c090-9932b8d0066c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training data:4096\n",
            "Generated samples   100/ 4096: Elapsed: 0:00:49\n",
            "Generated samples   200/ 4096: Elapsed: 0:01:40\n",
            "Generated samples   300/ 4096: Elapsed: 0:02:29\n",
            "Generated samples   400/ 4096: Elapsed: 0:03:19\n",
            "Generated samples   500/ 4096: Elapsed: 0:04:08\n",
            "Generated samples   600/ 4096: Elapsed: 0:04:56\n",
            "Generated samples   700/ 4096: Elapsed: 0:05:45\n",
            "Generated samples   800/ 4096: Elapsed: 0:06:34\n",
            "Generated samples   900/ 4096: Elapsed: 0:07:23\n",
            "Generated samples  1000/ 4096: Elapsed: 0:08:12\n",
            "Generated samples  1100/ 4096: Elapsed: 0:09:02\n"
          ]
        }
      ],
      "source": [
        "## Generate Training Data\n",
        "\n",
        "if LOCALDATA != True:\n",
        "  # Store time\n",
        "  print(f'Generating training data:{nSamples}')\n",
        "  tStarttime = time.time()\n",
        "\n",
        "  # Initialize a default lut (no grading applied)\n",
        "  default_lut = initLUT()\n",
        "\n",
        "  # LUT data holds all graded LUT tables and parameter targets are the parameters used for that LUT\n",
        "\n",
        "  lut_data = []\n",
        "  parameter_targets = []\n",
        "\n",
        "  # With 1-2 parameters we could still use even linear space distribution, left here for documentation\n",
        "  # P_SAT_step = (P_SAT_HIGH - P_SAT_LOW) / (nSamples - 1)\n",
        "  # P_CON_step = (P_CON_HIGH - P_CON_LOW) / (nSamples - 1)\n",
        "\n",
        "  # Init Quasirandom sampling\n",
        "  sobolSamples = initSpace(sobolSeed, nSamples)\n",
        "\n",
        "  current = 0\n",
        "  while current < nSamples:\n",
        "    # Get parametes from sequence generator\n",
        "    currentParameters = getAllParameters(current)\n",
        "    # P_SAT = P_SAT_LOW + (current * P_SAT_step)\n",
        "    # P_CON = P_CON_LOW + (current * P_CON_step)\n",
        "\n",
        "    lut_data.append(np.copy(default_lut))\n",
        "    applyGrade(lut_data[current], currentParameters)\n",
        "    parameter_targets.append(currentParameters)\n",
        "    #parameter_targets.append([P_SAT, P_CON])\n",
        "\n",
        "    if (current + 1) % 100 == 0:\n",
        "      tNow = str(timedelta(seconds=(time.time() - tStarttime))).split(\".\")[0]\n",
        "      print('Generated samples %5d/%5d: Elapsed: %s' %\n",
        "            (current + 1, nSamples, tNow))\n",
        "\n",
        "    current += 1\n",
        "\n",
        "  # Training data generation is done\n",
        "  tEndttime = time.time()\n",
        "  tDelta = timedelta(seconds=(tEndttime - tStarttime))\n",
        "\n",
        "  print('Generating training data has finished and took:', str(tDelta))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMpd5w_7sXOB"
      },
      "outputs": [],
      "source": [
        "if LOCALDATA != True and skipSave != True:\n",
        "  # Save generated training data locally\n",
        "  np.save(LUTSAMPLESFILE, lut_data)\n",
        "  print(f'Saved training samples to: {LUTSAMPLESFILE}')\n",
        "  np.save(PARAMETERSFILE, parameter_targets)\n",
        "  print(f'Saved parameter samples to: {PARAMETERSFILE}')\n",
        "\n",
        "\n",
        "  if DOWNLOAD==True:\n",
        "    # LUTSamples\n",
        "    files.download(LUTSAMPLESFILE)\n",
        "    # Parameters\n",
        "    files.download(PARAMETERSFILE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie9LSSiEVovr"
      },
      "outputs": [],
      "source": [
        "# For debugging and visualizations purposes, let's display a few random samples\n",
        "\n",
        "PREVIEW=True\n",
        "\n",
        "if PREVIEW==True:\n",
        "  idx = 0\n",
        "  while idx <= 4:\n",
        "    rndsample = random.randint(0, nSamples-1)\n",
        "    pp.imshow(lut_data[rndsample])\n",
        "    pp.show()\n",
        "    print('Parameter(s)', parameter_targets[rndsample],'\\n')\n",
        "    idx +=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HFUKxHDxvdk"
      },
      "source": [
        "Network training part"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare (normalize/transform) generated data for training"
      ],
      "metadata": {
        "id": "IlJRoNaEkVAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying to locate/upload pre-generated, normalized data\n",
        "LOCALDATA = False\n",
        "\n",
        "## Check if we have relevant training data locally\n",
        "SAMPLESPATH = './training_samples'\n",
        "LUTSAMPLESFILE = f'{SAMPLESPATH}/N_allsamples_{nSamples}_{nGradingParameters}_{sobolSeed}.npy'\n",
        "PARAMETERSFILE = f'{SAMPLESPATH}/N_allparameters_{nSamples}_{nGradingParameters}_{sobolSeed}.npy'\n",
        "\n",
        "if path.exists(SAMPLESPATH) == False:\n",
        "  LOCALDATA = False\n",
        "  os.mkdir(SAMPLESPATH)\n",
        "else:\n",
        "  print('Directory found')\n",
        "  if path.exists(LUTSAMPLESFILE) == False:\n",
        "    print(f'File: {LUTSAMPLESFILE} not found')\n",
        "    LOCALDATA = False\n",
        "  if path.exists(PARAMETERSFILE) == False:\n",
        "    print(f'File: {PARAMETERSFILE} not found')\n",
        "    LOCALDATA = False\n",
        "\n",
        "if LOCALDATA == False:\n",
        "  if UPLOADSAMPLES == True:\n",
        "    files.upload()\n",
        "\n",
        "if path.exists(LUTSAMPLESFILE) == True and path.exists(PARAMETERSFILE) == True:\n",
        "  LOCALDATA = True\n",
        "\n",
        "## Catch error (?)\n",
        "if LOCALDATA != True and LOCALDATA != False:\n",
        "  raise SystemExit(0)\n",
        "\n",
        "## Print status\n",
        "if LOCALDATA == True:\n",
        "  lut_data = np.load(LUTSAMPLESFILE)\n",
        "  print('Using pre-generated sample data from:',LUTSAMPLESFILE)\n",
        "  parameter_targets = np.load(PARAMETERSFILE)\n",
        "  print('Using pre-generated parameter data from:',PARAMETERSFILE)\n",
        "\n",
        "  # Check that the shape match\n",
        "  DATAOK = False\n",
        "  if lut_data.shape[0] == nSamples and lut_data.shape[1] == LUT_SIZE and lut_data.shape[2] == LUT_SIZE*LUT_SIZE and lut_data.shape[3] == 3:\n",
        "    if parameter_targets.shape[0] == nSamples and parameter_targets.shape[1] == nGradingParameters:\n",
        "      DATAOK = True\n",
        "\n",
        "  if DATAOK==False:\n",
        "    LOCALDATA = False\n",
        "    print('Error validating loaded data')\n",
        "    raise SystemExit(0)\n",
        "else:\n",
        "  print('No pre-generated data found')\n",
        "\n",
        "if forceSampleGeneration==True:\n",
        "  LOCALDATA = False\n"
      ],
      "metadata": {
        "id": "z1KjksOyZ86t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview of how packing of LUTS work\n",
        "dflut = initLUT()\n",
        "pp.imshow(dflut)\n",
        "pp.show()\n",
        "packLUT(dflut)\n",
        "pp.imshow(dflut)\n",
        "pp.show()\n",
        "unpackLUT(dflut)\n",
        "pp.imshow(dflut)\n",
        "pp.show()"
      ],
      "metadata": {
        "id": "H60pJdfzxUh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3gxCRY4dexb"
      },
      "outputs": [],
      "source": [
        "# Normalize and transform data\n",
        "\n",
        "# Adjust parameters to range 0..1\n",
        "def packParam01(param, low, high):\n",
        "  packed = (param-low) * (1.0 / (high-low))\n",
        "  return packed\n",
        "\n",
        "# Return parameter from range 0..1\n",
        "def unPackParam01(param, low, high):\n",
        "  unpacked = (param/(1.0 / (high-low))) + low\n",
        "  return unpacked\n",
        "\n",
        "parameter_targets = np.array(parameter_targets)\n",
        "\n",
        "def packParameters(packParameters, nParam):\n",
        "  idx = 0\n",
        "  while idx < nParam:\n",
        "    pLow = P_ALL_LOW[idx]\n",
        "    # Multiplier\n",
        "    mulP = 1.0 / (P_ALL_HIGH[idx] - pLow)\n",
        "    selectedP = packParameters[:,idx]\n",
        "    # Offset\n",
        "    selectedP -= pLow\n",
        "    # Multiply\n",
        "    selectedP *= mulP\n",
        "    idx+=1\n",
        "  return packParameters\n",
        "\n",
        "def unpackParameters(unpackParameters, nParam):\n",
        "  idx = 0\n",
        "  while idx < nParam:\n",
        "    pLow = P_ALL_LOW[idx]\n",
        "    # Multiplier\n",
        "    mulP = 1.0 / (P_ALL_HIGH[idx] - pLow)\n",
        "    selectedP = unpackParameters[:,idx]\n",
        "    # Offset\n",
        "    selectedP /= mulP\n",
        "    # Multiply\n",
        "    selectedP += pLow\n",
        "    idx+=1\n",
        "  return unpackParameters\n",
        "\n",
        "if LOCALDATA != True:\n",
        "  print(parameter_targets[0])\n",
        "  parameter_targets = packParameters(parameter_targets, nParameters)\n",
        "  print(parameter_targets[0])\n",
        "\n",
        "# This will transfer the LUT table in the format that all color components are 0.5, unless grading parameters have altered them\n",
        "def packLUT(lut):\n",
        "#  default_lut = np.zeros((16,256,3), dtype=np.float32)\n",
        "  r = 0\n",
        "  g = 0\n",
        "  b = 0\n",
        "  lutstep = 1/(LUT_SIZE -1)\n",
        "\n",
        "  for i in np.ndindex(lut.shape[:2]):\n",
        "  #  default_lut[i] = [r, g, b]\n",
        "  # Based on the step, shift each component based on their position\n",
        "\n",
        "    lut[i][0] = lut[i][0] + (0.5 - r)\n",
        "    lut[i][1] = lut[i][1] + (0.5 - g)\n",
        "    lut[i][2] = lut[i][2] + (0.5 - b)\n",
        "\n",
        "    r = r + lutstep\n",
        "    if (r >= 1):\n",
        "      r = 0\n",
        "      b = b + lutstep\n",
        "      if (b >= 1):\n",
        "        b = 0\n",
        "        g = g + lutstep\n",
        "\n",
        "\n",
        "def unpackLUT(lut):\n",
        "  r = 0\n",
        "  g = 0\n",
        "  b = 0\n",
        "  lutstep = 1/(LUT_SIZE -1)\n",
        "\n",
        "  for i in np.ndindex(lut.shape[:2]):\n",
        "  #  default_lut[i] = [r, g, b]\n",
        "  # Based on the step, shift each component based on their position\n",
        "\n",
        "    lut[i][0] = lut[i][0] - (0.5 - r)\n",
        "    lut[i][1] = lut[i][1] - (0.5 - g)\n",
        "    lut[i][2] = lut[i][2] - (0.5 - b)\n",
        "\n",
        "    r = r + lutstep\n",
        "    if (r >= 1):\n",
        "      r = 0\n",
        "      b = b + lutstep\n",
        "      if (b >= 1):\n",
        "        b = 0\n",
        "        g = g + lutstep\n",
        "\n",
        "#PREVIEW=True\n",
        "\n",
        "#if PREVIEW==True:\n",
        "#  idx = 0\n",
        "#  while idx <= 4:\n",
        "#    rndsample = random.randint(0, nSamples-1)\n",
        "#    pp.imshow(lut_data[rndsample])\n",
        "#    pp.show()\n",
        "#    print('Parameter(s)', parameter_targets[rndsample],'\\n')\n",
        "\n",
        "#    lut_data[rndsample]=packLUT(lut_data[rndsample])\n",
        "#    pp.imshow(lut_data[rndsample])\n",
        "#    pp.show()\n",
        "\n",
        "#    lut_data[rndsample]=unpackLUT(lut_data[rndsample])\n",
        "#    pp.imshow(lut_data[rndsample])\n",
        "#    pp.show()\n",
        "\n",
        "#    print('')\n",
        "\n",
        "#    idx +=1\n",
        "\n",
        "# Process all LUTs for training\n",
        "if LOCALDATA != True:\n",
        "  print(f'Generating training data:{nSamples}')\n",
        "  tStarttime = time.time()\n",
        "\n",
        "  idx = 0\n",
        "  while idx < nSamples:\n",
        "    packLUT(lut_data[idx])\n",
        "    idx +=1\n",
        "    if idx % 100 == 0:\n",
        "        tNow = str(timedelta(seconds=(time.time() - tStarttime))).split(\".\")[0]\n",
        "        print('Processed LUT samples for training %5d/%5d: Elapsed: %s' %\n",
        "              (idx, nSamples, tNow))\n",
        "\n",
        "  # LUT processing is done\n",
        "  tEndttime = time.time()\n",
        "  tDelta = timedelta(seconds=(tEndttime - tStarttime))\n",
        "\n",
        "  print('LUT processing done and took:', str(tDelta))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save normalized training data\n",
        "\n",
        "if LOCALDATA != True and skipSave != True:\n",
        "  # Save generated training data locally\n",
        "  np.save(LUTSAMPLESFILE, lut_data)\n",
        "  print(f'Saved training samples to: {LUTSAMPLESFILE}')\n",
        "  np.save(PARAMETERSFILE, parameter_targets)\n",
        "  print(f'Saved parameter samples to: {PARAMETERSFILE}')\n",
        "\n",
        "\n",
        "  if DOWNLOAD==True:\n",
        "    # LUTSamples\n",
        "    files.download(LUTSAMPLESFILE)\n",
        "    # Parameters\n",
        "    files.download(PARAMETERSFILE)\n"
      ],
      "metadata": {
        "id": "qrCcc26AZtwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEIzYaZl34jv"
      },
      "source": [
        "## Setup Neural Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdpZmmuk2uFc"
      },
      "outputs": [],
      "source": [
        "## Network dimension\n",
        "\n",
        "# LUT is 16 per axis and 3 channels (RGB) per pixel\n",
        "nInput = LUT_SIZE*LUT_SIZE*LUT_SIZE*3\n",
        "# Outputs are the grading parameters (amount depends on our used preset/settings)\n",
        "nOutput = nParameters\n",
        "\n",
        "# Check if there is existing model\n",
        "\n",
        "LOCALMODEL = False\n",
        "MODELPATH = './lut_'+DEMO+'_trained_net.pth'\n",
        "if skipModelRegeneration == True:\n",
        "  if path.exists(MODELPATH) == True:\n",
        "    LCOCALMODEL = True\n",
        "    print('Using pre-generated model, skipping next parts')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQpGwlRaLZuO"
      },
      "outputs": [],
      "source": [
        "# Define Dataset\n",
        "\n",
        "class LUTDataSet(Dataset):\n",
        "\n",
        "    ''' Init function, data=lut samples, targets=output parameters '''\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        self.data = torch.reshape(data, (len(data), nInput))\n",
        "        self.targets = torch.reshape(targets, (len(targets), nOutput))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return(len(self.data))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        lut = self.data[idx]\n",
        "        parameters = self.targets[idx]\n",
        "        return lut, parameters\n",
        "\n",
        "# Skip if we have a local version of the model\n",
        "if LOCALMODEL != True:\n",
        "  # Dataset takes Tensors - convert Numpy Arrays to Tensors\n",
        "  tParameters = torch.Tensor(parameter_targets)\n",
        "  tData = torch.Tensor(lut_data)\n",
        "\n",
        "  d = LUTDataSet(tData, tParameters)\n",
        "\n",
        "  # Initalize DataLoader\n",
        "  train_dataloader = DataLoader(d, batch_size=nBatchSize , shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVje71cI3Ss_"
      },
      "outputs": [],
      "source": [
        "## Definition of the NN Module\n",
        "\n",
        "class MLPcondensed(nn.Module):\n",
        "    '''\n",
        "    Multi-layer perceptron for non-linear regression.\n",
        "    '''\n",
        "    def __init__(self, nInput, nHidden, nOutput):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(nInput, nHidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(nHidden, nHidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(nHidden, nHidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(nHidden, nOutput)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return(self.layers(x))\n",
        "\n",
        "model = MLPcondensed(nInput, nHidden, nOutput)\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om6JVzY94661"
      },
      "source": [
        "## Run Training\n",
        "\n",
        "What to expect from Google Colab\n",
        "\n",
        "1 parameter, 128 samples, 10 hidden, 2 000 steps: 42 seconds (CPU) - Loss: 0.000\n",
        "\n",
        "2 parameters, 256 samples, 16 hidden, 3 000 steps: 2min 39s (CPU) - Loss: 0.001\n",
        "\n",
        "2 parameters, 256 samples, 16 hidden, 3 000 steps: 1min 7s (T4 GPU) - Loss: 0.001\n",
        "\n",
        "5 parameters, 512 samples, 16 hidden, 15 000 steps: 47min (CPU) - Loss: 0.448\n",
        "\n",
        "5 parameters, 512 samples, 16 hidden, 15 000 steps: 39min (TPU) - Loss: 0.127 (why?)\n",
        "\n",
        "5 parameters, 512 samples, 16 hidden, 15 000 steps: 11min (T4 GPU) - Loss (1): 0.203, Loss (2): 0.140 (why?)\n",
        "\n",
        "10 parameters, 1024 samples, 48 hidden, 50 000 steps, Batch size 64: 49 min (T4 GPU) - Loss after 1000 epoch: 0.213 - Loss after 50 000 epoch: 0.036\n",
        "\n",
        "10 parameters, 1024 samples, 48 hidden, 50 000 steps, Batch size 32 : 67 min (Local 4070Ti) - Loss after 50 000 epoch: 0.077"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O-BCzUfgSnU"
      },
      "outputs": [],
      "source": [
        "# Skip if we have a local version of the model\n",
        "if LOCALMODEL != True:\n",
        "\n",
        "  # Store time for statistics\n",
        "  tStarttime = time.time()\n",
        "\n",
        "  # Define the loss function and optimizer\n",
        "  loss_function = nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lRate)\n",
        "\n",
        "  # Set the model to train mode\n",
        "  model.train()\n",
        "\n",
        "  # Run the training loop\n",
        "  for epoch in range(0, nTrainSteps):\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "\n",
        "      # Data\n",
        "      inputs, targets = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      # Training\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = loss_function(outputs, targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Statistics\n",
        "      current_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        tNow = str(timedelta(seconds=(time.time() - tStarttime))).split(\".\")[0]\n",
        "        print('Loss after epoch %5d/%5d: %.3f - Elapsed: %s' %\n",
        "              (epoch + 1, nTrainSteps, current_loss, tNow))\n",
        "\n",
        "        current_loss = 0.0\n",
        "\n",
        "  # Process is complete.\n",
        "  tEndttime = time.time()\n",
        "  tDelta = timedelta(seconds=(tEndttime - tStarttime))\n",
        "\n",
        "  print('Training process has finished and took:', str(tDelta))\n",
        "\n",
        "  # Save the model locally\n",
        "  # PATH = './lut_trained_net.pth'\n",
        "  torch.save(model.state_dict(), MODELPATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejkuKYO45sHL"
      },
      "source": [
        "## Benchmark model and plot results\n",
        "\n",
        "> Sisennetty osio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ow5alAGT8MU"
      },
      "outputs": [],
      "source": [
        "# Let's test our model\n",
        "\n",
        "# Create random parameters for a new LUT to be tested with the model\n",
        "# These parameters should match the training data\n",
        "\n",
        "## Generate Training Data\n",
        "test_lut = initLUT()\n",
        "\n",
        "# For plotting\n",
        "gen_PARAM = np.zeros(shape=(nTests, nParameters))\n",
        "net_PARAM = np.zeros(shape=(nTests, nParameters))\n",
        "\n",
        "# Load model\n",
        "net = MLPcondensed(nInput, nHidden, nOutput)\n",
        "net.load_state_dict(torch.load(MODELPATH))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "net.eval()\n",
        "\n",
        "# Local path for LUTS\n",
        "if path.exists('./LUTS') == False:\n",
        "  os.mkdir('./LUTS')\n",
        "LUTPATH = './LUTS/'\n",
        "\n",
        "current = 0\n",
        "while current < nTests:\n",
        "  # Create a random LUT\n",
        "  param = randomParameters()\n",
        "  currentLUT = np.copy(test_lut)\n",
        "  applyGrade(currentLUT, param)\n",
        "  LUTforModel = np.copy(currentLUT)\n",
        "\n",
        "  # We need to pack this\n",
        "  packLUT(LUTforModel)\n",
        "\n",
        "  # Run in through the  model\n",
        "  tData = torch.Tensor(LUTforModel)\n",
        "  # We are giving just one sample to our model\n",
        "  tData = torch.reshape(tData, (1, nInput))\n",
        "  output = net(tData)\n",
        "\n",
        "  # For plotting\n",
        "  # We need dedicated copy for plotting purposes\n",
        "  outputnp = output.detach().numpy()#[0]\n",
        "  # Model output needs to be unpacked (only one parameter needed to unpack)\n",
        "  outputnp = unpackParameters(outputnp,nParameters)[0]\n",
        "  gen_PARAM[current] = param\n",
        "  net_PARAM[current] = outputnp\n",
        "\n",
        "  # Preview and store every n:th LUT test\n",
        "  if (current) % 25 == 0:\n",
        "     print('Test number: ', current)\n",
        "     pp.imshow(currentLUT)\n",
        "     pp.show()\n",
        "     print('')\n",
        "     viewStr = createParameterString(outputnp, param)\n",
        "     print('Parameter output from model vs groundtruth:', viewStr)\n",
        "     print(' ')\n",
        "     # Save locally\n",
        "     SAVEPATH = LUTPATH+viewStr+'.png'\n",
        "     pp.imsave(SAVEPATH, currentLUT)\n",
        "\n",
        "  current += 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qFCPiQbF4AP"
      },
      "outputs": [],
      "source": [
        "# Create plot\n",
        "\n",
        "# Plot\n",
        "\n",
        "pp.rcParams.update({'figure.figsize':(8,8), 'figure.dpi':100})\n",
        "if nGradingParameters == 12:\n",
        "  pp.scatter(gen_PARAM[:,0], net_PARAM[:,0], s=4, c='#ffbbbb', label=f'Sat R Cor. = {np.round(np.corrcoef(gen_PARAM[:,0],net_PARAM[:,0])[0,1], 4)}')\n",
        "  pp.scatter(gen_PARAM[:,1], net_PARAM[:,1], s=4, c='#ff9999', label=f'Sat G Cor. = {np.round(np.corrcoef(gen_PARAM[:,1],net_PARAM[:,1])[0,1], 4)}')\n",
        "  pp.scatter(gen_PARAM[:,2], net_PARAM[:,2], s=4, c='#ff6666', label=f'Sat B Cor. = {np.round(np.corrcoef(gen_PARAM[:,2],net_PARAM[:,2])[0,1], 4)}')\n",
        "\n",
        "  pp.scatter(gen_PARAM[:,3], net_PARAM[:,3], s=4, c='#ffbbff', label=f'Con R Cor. = {np.round(np.corrcoef(gen_PARAM[:,3],net_PARAM[:,3])[0,1], 4)}')\n",
        "  pp.scatter(gen_PARAM[:,4], net_PARAM[:,4], s=4, c='#ff99ff', label=f'Con G Cor. = {np.round(np.corrcoef(gen_PARAM[:,4],net_PARAM[:,4])[0,1], 4)}')\n",
        "  pp.scatter(gen_PARAM[:,5], net_PARAM[:,5], s=4, c='#ff66ff', label=f'Con B Cor. = {np.round(np.corrcoef(gen_PARAM[:,5],net_PARAM[:,5])[0,1], 4)}')\n",
        "\n",
        "  pp.scatter(gen_PARAM[:,6], net_PARAM[:,6], s=4, c='#bbffbb', label=f'Gam R Cor. = {np.round(np.corrcoef(gen_PARAM[:,6],net_PARAM[:,6])[0,1], 4)}')\n",
        "  pp.scatter(gen_PARAM[:,7], net_PARAM[:,7], s=4, c='#99ff99', label=f'Gam G Cor. = {np.round(np.corrcoef(gen_PARAM[:,7],net_PARAM[:,7])[0,1], 4)}')\n",
        "  pp.scatter(gen_PARAM[:,8], net_PARAM[:,8], s=4, c='#66ff66', label=f'Gam B Cor. = {np.round(np.corrcoef(gen_PARAM[:,8],net_PARAM[:,8])[0,1], 4)}')\n",
        "\n",
        "  pp.scatter(gen_PARAM[:,9], net_PARAM[:,9], s=4, c='#bbbbff', label=f'Gin R Cor. = {np.round(np.corrcoef(gen_PARAM[:,9],net_PARAM[:,9])[0,1], 4)}')\n",
        "  pp.scatter(gen_PARAM[:,10], net_PARAM[:,10], s=4, c='#9999ff', label=f'Gin G Cor. = {np.round(np.corrcoef(gen_PARAM[:,10],net_PARAM[:,10])[0,1], 4)}')\n",
        "  pp.scatter(gen_PARAM[:,11], net_PARAM[:,11], s=4, c='#6666ff', label=f'Gin B Cor. = {np.round(np.corrcoef(gen_PARAM[:,11],net_PARAM[:,11])[0,1], 4)}')\n",
        "else:\n",
        "  pp.scatter(gen_PARAM[:,0], net_PARAM[:,0], s=8, c='#ff0000', label=f'Sat W Cor. = {np.round(np.corrcoef(gen_PARAM[:,0],net_PARAM[:,0])[0,1], 4)}')\n",
        "  if nGradingParameters > 1:\n",
        "    pp.scatter(gen_PARAM[:,1], net_PARAM[:,1], s=8, c='#0000ff', label=f'Con Cor. = {np.round(np.corrcoef(gen_PARAM[:,1],net_PARAM[:,1])[0,1], 4)}')\n",
        "  if nGradingParameters > 2:\n",
        "    pp.scatter(gen_PARAM[:,2], net_PARAM[:,2], s=4, c='#ffbbbb', label=f'Sat R Cor. = {np.round(np.corrcoef(gen_PARAM[:,2],net_PARAM[:,2])[0,1], 4)}')\n",
        "    pp.scatter(gen_PARAM[:,3], net_PARAM[:,3], s=4, c='#ff9999', label=f'Sat G Cor. = {np.round(np.corrcoef(gen_PARAM[:,3],net_PARAM[:,3])[0,1], 4)}')\n",
        "    pp.scatter(gen_PARAM[:,4], net_PARAM[:,4], s=4, c='#ff6666', label=f'Sat B Cor. = {np.round(np.corrcoef(gen_PARAM[:,4],net_PARAM[:,4])[0,1], 4)}')\n",
        "  if nGradingParameters > 5:\n",
        "    pp.scatter(gen_PARAM[:,5], net_PARAM[:,5], s=8, c='#ff00ff', label=f'Gamma Cor. = {np.round(np.corrcoef(gen_PARAM[:,5],net_PARAM[:,5])[0,1], 4)}')\n",
        "    pp.scatter(gen_PARAM[:,6], net_PARAM[:,6], s=8, c='#00ff00', label=f'Gain W Cor. = {np.round(np.corrcoef(gen_PARAM[:,6],net_PARAM[:,6])[0,1], 4)}')\n",
        "    pp.scatter(gen_PARAM[:,7], net_PARAM[:,7], s=8, c='#bbffbb', label=f'Gain R Cor. = {np.round(np.corrcoef(gen_PARAM[:,7],net_PARAM[:,7])[0,1], 4)}')\n",
        "    pp.scatter(gen_PARAM[:,8], net_PARAM[:,8], s=8, c='#99ffff', label=f'Gain G Cor. = {np.round(np.corrcoef(gen_PARAM[:,8],net_PARAM[:,8])[0,1], 4)}')\n",
        "    pp.scatter(gen_PARAM[:,9], net_PARAM[:,9], s=8, c='#66ff66', label=f'Gain B Cor. = {np.round(np.corrcoef(gen_PARAM[:,9],net_PARAM[:,9])[0,1], 4)}')\n",
        "pp.title('Parameter Correlation - Samples: '+str(nSamples)+' Steps: '+str(nTrainSteps)+' Training: '+str(tDelta).split(\".\")[0])\n",
        "pp.legend()\n",
        "pp.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEuW67Z-S58W"
      },
      "source": [
        "## Export and download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7tqdu7fbR9T"
      },
      "outputs": [],
      "source": [
        "## Export and download data in ONNX format\n",
        "\n",
        "EXPORT=True\n",
        "\n",
        "if EXPORT==True:\n",
        "\n",
        "  %pip install onnx\n",
        "  %pip install onnxscript\n",
        "\n",
        "  #PATH = './lut_trained_net.pth'\n",
        "  EXPORTPATH = './LUTmodel'+DEMO+'.onnx'\n",
        "\n",
        "  # Load model\n",
        "  exportModel = MLPcondensed(nInput, nHidden, nOutput)\n",
        "  exportModel.load_state_dict(torch.load(MODELPATH))\n",
        "\n",
        "  # Initialize model with default LUT (needed for ONNX export)\n",
        "  defaultLUT = initLUT()\n",
        "  tData = torch.Tensor(defaultLUT)\n",
        "  # We are giving just one sample to our model\n",
        "  tData = torch.reshape(tData, (1, nInput))\n",
        "\n",
        "  # We are using older export function as dynamo_export version didn't work in UE (5.3)\n",
        "  # By the time of writing, both Pytorch dynamo_export\n",
        "  # And Unreal NNE were experimental, so either one could be the culprit\n",
        "\n",
        "  onnx = torch.onnx.export(exportModel, tData, EXPORTPATH)\n",
        "  #onnx = torch.onnx.dynamo_export(exportModel, tData)\n",
        "  #onnx.save(EXPORTPATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq8tjdqmifkV"
      },
      "outputs": [],
      "source": [
        "# Download (if not running locally, ie. Google Colab)\n",
        "if DOWNLOAD==True:\n",
        "\n",
        "  # Created Onnx model\n",
        "  files.download(EXPORTPATH)\n",
        "\n",
        "  # Pack LUT folder for download\n",
        "  !zip -r ./LUTsamples.zip ./LUTS/\n",
        "  files.download('./LUTsamples.zip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misc Tests"
      ],
      "metadata": {
        "id": "05g11wEqIO2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare LUT to image and parameters (from LUT) to image\n",
        "import math\n",
        "\n",
        "# Define functions\n",
        "def imgfile2array(img):\n",
        "  im = util.img_as_float(Image.open(img))\n",
        "  return im\n",
        "\n",
        "def IndexXY(r, g, b):\n",
        "#  x = r # red = x axis, repeating on every 16 patch\n",
        "  y = g # green = along y axis\n",
        "  x = r + (b * 16) # blue = multiplied by 16\n",
        "  return int(x), int(y)\n",
        "\n",
        "def mix(a, b, c):\n",
        "    c = c - math.floor(c)\n",
        "    return (1.0 - c) * a + c * b\n",
        "    #return a + (b - a) * (c - math.floor(c))\n",
        "\n",
        "def applyLUT(img, lut):\n",
        "  #for x in img:\n",
        "  #  for y in x:\n",
        "  for iy in range(img.shape[0]):\n",
        "    for ix in range(img.shape[1]):\n",
        "      pixelCol = img[iy, ix].astype(float)\n",
        "\n",
        "      pix_r = pixelCol[0] * 15.0\n",
        "      pix_g = pixelCol[1] * 15.0\n",
        "      pix_b = pixelCol[2] * 15.0\n",
        "\n",
        "      rH = math.ceil(pix_r)\n",
        "      rL = math.floor(pix_r)\n",
        "      gH = math.ceil(pix_g)\n",
        "      gL = math.floor(pix_g)\n",
        "      bH = math.ceil(pix_b)\n",
        "      bL = math.floor(pix_b)\n",
        "\n",
        "      iHx, iHy = IndexXY(rH, gH, bH)\n",
        "      iLx, iLy = IndexXY(rL, gL, bL)\n",
        "\n",
        "      ColH = lut[iHy][iHx].astype(float)\n",
        "      ColL = lut[iLy][iLx].astype(float)\n",
        "\n",
        "      r = mix(ColL[0], ColH[0], pix_r).astype(float)\n",
        "      g = mix(ColL[1], ColH[1], pix_g).astype(float)\n",
        "      b = mix(ColL[2], ColH[2], pix_b).astype(float)\n",
        "\n",
        "      img[iy, ix] = [r,g,b]\n",
        "  np.clip(img, 0.0, 1.0, out=img)\n",
        "\n"
      ],
      "metadata": {
        "id": "U2dFJ-OfIUmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create random LUT comparison\n",
        "nLutTests = 5\n",
        "testfile = './testfiles/sevillapark_640_8bit_srgb.png'\n",
        "\n",
        "testimage = imgfile2array(testfile)\n",
        "testlut = initLUT()\n",
        "\n",
        "current = 0\n",
        "while current < nLutTests:\n",
        "\n",
        "  t_img1 = np.copy(testimage)\n",
        "  t_img2 = np.copy(testimage)\n",
        "  t_img3 = np.copy(testimage)\n",
        "  t_img4 = np.copy(testimage)\n",
        "\n",
        "  param = randomParameters()\n",
        "\n",
        "  currentLUT = np.copy(test_lut)\n",
        "  applyGrade(currentLUT, param)\n",
        "\n",
        "  LUTforModel = np.copy(currentLUT)\n",
        "  # We need to pack this\n",
        "  packLUT(LUTforModel)\n",
        "  # Run in through the  model\n",
        "  tData = torch.Tensor(LUTforModel)\n",
        "  # We are giving just one sample to our model\n",
        "  tData = torch.reshape(tData, (1, nInput))\n",
        "  output = net(tData)\n",
        "  # For plotting\n",
        "  # We need dedicated copy for plotting purposes\n",
        "  outputnp = output.detach().numpy()#[0]\n",
        "  # Model output needs to be unpacked (only one parameter needed to unpack)\n",
        "  outputnp = unpackParameters(outputnp,nParameters)[0]\n",
        "\n",
        "  ## Images graded with parameters\n",
        "  # 1: Groundtruth, 2: From model\n",
        "  applyGrade(t_img1, param)\n",
        "  applyGrade(t_img2, outputnp)\n",
        "\n",
        "  ## Images graded with LUTS\n",
        "  # 3:\n",
        "  applyLUT(t_img3, currentLUT)\n",
        "\n",
        "  modelLUT = np.copy(test_lut)\n",
        "  applyGrade(modelLUT, outputnp)\n",
        "  applyLUT(t_img4, modelLUT)\n",
        "\n",
        "  #viewStr = createParameterString(outputnp, param)\n",
        "  #print('Parameter output from model vs groundtruth:', viewStr)\n",
        "  print('Groundtruth parameters:', param)\n",
        "  print('Model output parameters:', outputnp)\n",
        "\n",
        "  f, axarr = pp.subplots(1,2)\n",
        "  axarr[0].imshow(t_img1)\n",
        "  axarr[1].imshow(t_img2)\n",
        "  pp.show()\n",
        "  f, axarr = pp.subplots(1,2)\n",
        "  axarr[0].imshow(t_img3)\n",
        "  axarr[1].imshow(t_img4)\n",
        "  pp.show()\n",
        "  f, axarr = pp.subplots(1,2)\n",
        "  axarr[0].imshow(currentLUT)\n",
        "  axarr[1].imshow(modelLUT)\n",
        "  pp.show()\n",
        "  current += 1\n"
      ],
      "metadata": {
        "id": "-xbJNaXkes3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test and compare all LUTS in dedicated folder\n",
        "TESTPATH = './testLUTS/'\n",
        "\n",
        "testfile = './testfiles/sevillapark_640_8bit_srgb.png'\n",
        "testimage = imgfile2array(testfile)\n",
        "\n",
        "if path.exists(TESTPATH) == True:\n",
        "    print('Test LUTS path found. Iterating over all LUT files')\n",
        "    for subdir, dirs, files in os.walk(TESTPATH):\n",
        "        for file in files:\n",
        "            testlutpath = subdir + os.sep + file\n",
        "\n",
        "            if testlutpath.endswith(\".png\") or testlutpath.endswith(\".PNG\"):\n",
        "\n",
        "                # Print LUT data\n",
        "                print (testlutpath)\n",
        "                testLUT = imgfile2array(testlutpath)\n",
        "                # Drop alpha channel off\n",
        "                testLUT = testLUT[:,:,:3]\n",
        "                print (np.shape(testLUT))\n",
        "                pp.imshow(testLUT)\n",
        "                pp.show()\n",
        "\n",
        "                t_img1 = np.copy(testimage)\n",
        "                t_img2 = np.copy(testimage)\n",
        "\n",
        "                applyLUT(t_img1, testLUT)\n",
        "\n",
        "                LUTforModel = np.copy(testLUT)\n",
        "                # We need to pack this\n",
        "                packLUT(LUTforModel)\n",
        "                # Run in through the  model\n",
        "                tData = torch.Tensor(LUTforModel)\n",
        "                # We are giving just one sample to our model\n",
        "                tData = torch.reshape(tData, (1, nInput))\n",
        "                output = net(tData)\n",
        "                # For plotting\n",
        "                # We need dedicated copy for plotting purposes\n",
        "                outputnp = output.detach().numpy()#[0]\n",
        "                # Model output needs to be unpacked (only one parameter needed to unpack)\n",
        "                outputnp = unpackParameters(outputnp,nParameters)[0]\n",
        "\n",
        "                # Grade test image with modelled parameters\n",
        "                applyGrade(t_img2, outputnp)\n",
        "\n",
        "                print(\"Image graded with LUT vs Model parameters\")\n",
        "                f, axarr = pp.subplots(1,2)\n",
        "                axarr[0].imshow(t_img1)\n",
        "                axarr[1].imshow(t_img2)\n",
        "                pp.show()\n",
        "                print(outputnp)"
      ],
      "metadata": {
        "id": "dSVoi_Htb3nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cTdx9moqVUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O5uiyloMmjY"
      },
      "source": [
        "## Misc debug functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM-oG698yqvF"
      },
      "outputs": [],
      "source": [
        "# Display Graded LUT for debug purposes\n",
        "\n",
        "DEBUG=False\n",
        "\n",
        "if DEBUG==True:\n",
        "  debuglut=initLUT()\n",
        "  debugparameters=initParameters()\n",
        "\n",
        "#P_SAT\n",
        "  debugparameters[0]=1.11318099\n",
        "#P_CON\n",
        "  if nGradingParameters > 1:\n",
        "   debugparameters[1]=0.75725073\n",
        "#P_SAT_RGB\n",
        "  if nGradingParameters > 2:\n",
        "   debugparameters[2]=0.91048408\n",
        "#    debugparameters[3]=1.28483582\n",
        "#    debugparameters[4]=0.97269809\n",
        "  if nGradingParameters > 5:\n",
        "#P_GAM\n",
        "   debugparameters[5]=1.30009198\n",
        "#P_GIN\n",
        "#     debugparameters[6]=1.22534573\n",
        "#     debugparameters[7]=0.75790048\n",
        "#     debugparameters[8]=1.22956824\n",
        "#     debugparameters[9]=1.2244544\n",
        "\n",
        "  applyGrade(debuglut, debugparameters)\n",
        "  pp.imshow(debuglut)\n",
        "  pp.show()\n",
        "  print('parameter(s)', debugparameters,'\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZArBgFYIgFuf"
      },
      "outputs": [],
      "source": [
        "# Debug Dataset\n",
        "DEBUG=False\n",
        "\n",
        "if DEBUG==True:\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "      input, target = data\n",
        "      print('Input Shape', input.shape)\n",
        "      print('Target Shape', target.shape)\n",
        "  #    print('Size', input.Size)\n",
        "      print('Input 0 Shape', input[0].shape)\n",
        "\n",
        "      #print(\"In: \", input)\n",
        "      #print(\"Out:\", target,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I56J19-HOnyt"
      },
      "outputs": [],
      "source": [
        "# Debug Model\n",
        "DEBUG=False\n",
        "\n",
        "if DEBUG==True:\n",
        "  print (model)\n",
        "  for param in model.parameters():\n",
        "   print(param)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMBAYH32lwUkheVuTLQa9/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}